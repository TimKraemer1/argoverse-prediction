{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Specific Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Other\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "# Gaussian Blur\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# Model imports\n",
    "from DatasetClass import TrajectoryDatasetTest, TrajectoryDatasetTrain\n",
    "from models.LSTMAttentionModelClass import LSTMAttention\n",
    "from models.LinearRegressionModelClass import LinearRegressionModel\n",
    "from models.CNNModelClass import CNNModel\n",
    "from models.MLPModelClass import MLPModel\n",
    "from models.LSTMModelClass import LSTMModel\n",
    "from models.LSTMMultiHeadClass import LSTMMultiHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('cse-251-b-2025/input/train.npz')['data']\n",
    "test_data  = np.load('cse-251-b-2025/input/test_input.npz')['data']\n",
    "\n",
    "X_train = train_data[..., :50, :] # Input (scenes, agents, first 50 timesteps, features)\n",
    "Y_train = train_data[:, 0, 50:, :2] # Output (scenes, ego car, next 60 timesteps, x/y coordinates)\n",
    "\n",
    "# Print input and output data shape\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used from midquarter checkpoint for simplicity and consistency\n",
    "torch.manual_seed(251)\n",
    "np.random.seed(42)\n",
    "\n",
    "scale = 7.0\n",
    "\n",
    "N = len(train_data)\n",
    "val_size = int(0.1 * N)\n",
    "train_size = N - val_size\n",
    "\n",
    "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
    "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "\n",
    "device = torch.device('mps')\n",
    "print(\"Using Apple Silicon GPU\")\n",
    "\n",
    "print(train_dataset[0].x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'LSTM'\n",
    "match model_type:\n",
    "    case 'LinearRegression':\n",
    "        model = LinearRegressionModel().to(device)\n",
    "    case 'MLP':\n",
    "        model = MLPModel(6*50, 60 * 2).to(device)\n",
    "    case 'CNN':\n",
    "        model = CNNModel().to(device)\n",
    "    case 'LSTM':\n",
    "        model = LSTMModel().to(device)\n",
    "    case 'LSTMAttention':\n",
    "        model = LSTMAttention().to(device)\n",
    "    case 'LSTMMultiHead':\n",
    "        model = LSTMMultiHead().to(device)\n",
    "    \n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "# scheduler\n",
    "step = 1\n",
    "gamma = 0.50\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step, gamma)\n",
    "\n",
    "\n",
    "early_stopping_patience = 20\n",
    "best_val_loss = float('inf')\n",
    "no_improvement = 0\n",
    "\n",
    "# Criterion MSE\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mae_list = []\n",
    "val_mse_list = []\n",
    "epochs = 200\n",
    "for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    train_mse = 0\n",
    "    train_mae = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "        loss = criterion(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        train_mse += loss.item()\n",
    "        train_mae += nn.L1Loss()(pred, y).item()\n",
    "    \n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    val_mse = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "            val_mse += criterion(pred, y).item()\n",
    "\n",
    "            # show MAE and MSE with unnormalized data\n",
    "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "            val_mae += nn.L1Loss()(pred, y).item()\n",
    "            val_mse += nn.MSELoss()(pred, y).item()\n",
    "    \n",
    "    train_mse /= len(train_dataloader)\n",
    "    train_mae /= len(train_dataloader)\n",
    "    val_mae /= len(val_dataloader)\n",
    "    val_mse /= len(val_dataloader)\n",
    "\n",
    "    val_mae_list.append(val_mae)\n",
    "    val_mse_list.append(val_mse)\n",
    "    \n",
    "    tqdm.tqdm.write(f\"Epoch {epoch:03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train MSE {train_mse:8.4f} | train MAE {train_mae:8.4f}, | val MSE {val_mse:8.4f} | val MAE {val_mae:8.4f}\")\n",
    "    if val_loss < best_val_loss - 1e-3:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    else:\n",
    "        # scheduler decay \n",
    "        no_improvement += 1\n",
    "        if no_improvement == early_stopping_patience // 2:\n",
    "            print(\"Learning rate decay\")\n",
    "            scheduler.step()\n",
    "        # early stop\n",
    "        if no_improvement >= early_stopping_patience:\n",
    "            print(\"Early stop!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectory Plotting\n",
    "def plot_trajectory(ax, pred, gt, title=None):\n",
    "    ax.cla()\n",
    "    # Plot the predicted future trajectory\n",
    "    ax.plot(pred[0,:60,0], pred[0,:60,1], color='red', label='Predicted Future Trajectory')\n",
    "    \n",
    "    # Plot the ground truth future trajectory\n",
    "    ax.plot(gt[0,:60,0], gt[0,:60,1], color='blue', label='Ground Truth Future Trajectory')\n",
    "    \n",
    "    x_max = max(pred[..., 0].max(), gt[..., 0].max())\n",
    "    x_min = min(pred[..., 0].min(), gt[..., 0].min())\n",
    "    y_max = max(pred[..., 1].max(), gt[..., 1].max())\n",
    "    y_min = min(pred[..., 1].min(), gt[..., 1].min())\n",
    "    \n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# randomly select 4 samples from the validation set\n",
    "random_indices = random.sample(range(len(val_dataset)), 4)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "axes = axes.flatten()  # Flatten the array to iterate single axes objects\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    batch = val_dataset[idx]\n",
    "    batch = batch.to(device)\n",
    "    pred = model(batch)\n",
    "    gt = torch.stack(torch.split(batch.y, 60, dim=0), dim=0)\n",
    "\n",
    "    pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "    gt = torch.stack(torch.split(batch.y, 60, dim=0), dim=0) * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    gt = gt.detach().cpu().numpy()\n",
    "\n",
    "    # Plot the trajectory using the i-th axis\n",
    "    plot_trajectory(axes[i], pred, gt, title=f\"Sample {idx}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
    "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
    "\n",
    "best_model = torch.load(\"best_model.pt\")\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred_norm = model(batch)\n",
    "        \n",
    "        # Reshape the prediction to (N, 60, 2)\n",
    "        pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
    "\n",
    "        # Apply Gaussian smoothing along the time dimension (axis=1)\n",
    "        pred_numpy = pred.cpu().numpy()\n",
    "        pred_smoothed = np.zeros_like(pred_numpy)\n",
    "\n",
    "        #Smooth x and y\n",
    "        pred_smoothed[:, :, 0] = gaussian_filter1d(pred_numpy[:, :, 0], sigma=0.8, axis=1)\n",
    "        pred_smoothed[:, :, 1] = gaussian_filter1d(pred_numpy[:, :, 1], sigma=0.8, axis=1)\n",
    "        \n",
    "        pred_list.append(pred_smoothed)\n",
    "        \n",
    "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
    "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('submission06-01-2025.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
